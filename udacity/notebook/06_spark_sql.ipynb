{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4a548f4",
   "metadata": {},
   "source": [
    "# # Answer Key to the Data Wrangling with Spark SQL Quiz\n",
    "Este questionário usa o mesmo conjunto de dados e a maioria das mesmas perguntas do \"Questionário - Organização de dados com frames de dados do Jupyter Notebook\" anterior. Para este questionário, no entanto, use Spark SQL em vez de quadros de dados Spark.\n",
    "\n",
    "Recursos úteis:\n",
    "http://spark.apache.org/docs/latest/api/python/pyspark.sql.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fcf3921",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8077590b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName('Spark SQL quiz') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1ce28aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_log = spark.read.json(\"data/sparkify_log_small.json\")\n",
    "user_log.createOrReplaceTempView('table')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0427a429",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "\n",
    "Which page did user id \"\" (empty string) NOT visit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "407dbc4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist: string (nullable = true)\n",
      " |-- auth: string (nullable = true)\n",
      " |-- firstName: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- itemInSession: long (nullable = true)\n",
      " |-- lastName: string (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- method: string (nullable = true)\n",
      " |-- page: string (nullable = true)\n",
      " |-- registration: long (nullable = true)\n",
      " |-- sessionId: long (nullable = true)\n",
      " |-- song: string (nullable = true)\n",
      " |-- status: long (nullable = true)\n",
      " |-- ts: long (nullable = true)\n",
      " |-- userAgent: string (nullable = true)\n",
      " |-- userId: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_log.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13641b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------------+\n",
      "|page|            page|\n",
      "+----+----------------+\n",
      "|null|Submit Downgrade|\n",
      "|null|       Downgrade|\n",
      "|null|          Logout|\n",
      "|null|   Save Settings|\n",
      "|null|        Settings|\n",
      "|null|        NextSong|\n",
      "|null|         Upgrade|\n",
      "|null|           Error|\n",
      "|null|  Submit Upgrade|\n",
      "+----+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SELECT distinct pages for the blank user and distinc pages for all users\n",
    "# Right join the results to find pages that blank visitor did not visit\n",
    "spark.sql(\"select * \\\n",
    "            from ( \\\n",
    "                select distinct page \\\n",
    "                from table \\\n",
    "                where userId =='') as user_pages \\\n",
    "            right join( \\\n",
    "                select distinct page \\\n",
    "                from table) as all_pages \\\n",
    "            on user_pages.page = all_pages.page \\\n",
    "            where user_pages.page is null\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdb8760",
   "metadata": {},
   "source": [
    "# Question 2 - Reflect\n",
    "\n",
    "Por que você pode preferir usar SQL em vez de frames de dados? Por que você pode preferir frames de dados em vez de SQL?\n",
    "\n",
    "Tanto Spark SQL quanto Spark Data Frames fazem parte da biblioteca Spark SQL. Portanto, ambos usam o Spark SQL Catalyst Optimizer para otimizar as consultas.\n",
    "\n",
    "Você pode preferir SQL em vez de frames de dados porque a sintaxe é mais clara, especialmente para equipes já experientes em SQL.\n",
    "\n",
    "Os frames de dados do Spark oferecem mais controle. Você pode dividir suas consultas em etapas menores, o que pode tornar a depuração mais fácil. Você também pode [armazenar em cache] (https://unraveldata.com/to-cache-or-not-to-cache/) resultados intermediários ou [reparticionar] (https://hackernoon.com/managing-spark-partitions-with -coalesce-and-repartition-4050c57ad5c4) resultados intermediários."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e5d36a",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "\n",
    "Quantas usuárias temos no conjunto de dados?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46087c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+\n",
      "|count(DISTINCT userId)|\n",
      "+----------------------+\n",
      "|                   462|\n",
      "+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select count(distinct userId) \\\n",
    "            from table \\\n",
    "            where gender = 'F'\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b713d14",
   "metadata": {},
   "source": [
    "# Question 4\n",
    "\n",
    "Quantas músicas do artista mais tocado foram tocadas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a987502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|  Artist|plays|\n",
      "+--------+-----+\n",
      "|Coldplay|   83|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# here is one solution\n",
    "spark.sql(\"select Artist, count(artist) as plays \\\n",
    "    from table \\\n",
    "    group by Artist \\\n",
    "    order by plays desc \\\n",
    "    limit 1\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abc2fff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|  Artist|plays|\n",
      "+--------+-----+\n",
      "|Coldplay|   83|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Here is an alternative solution\n",
    "# Get the artist play counts\n",
    "play_counts = spark.sql(\"SELECT Artist, COUNT(Artist) AS plays \\\n",
    "        FROM table \\\n",
    "        GROUP BY Artist\")\n",
    "\n",
    "# save the results in a new view\n",
    "play_counts.createOrReplaceTempView(\"artist_counts\")\n",
    "\n",
    "# use a self join to find where the max play equals the count value\n",
    "spark.sql(\"SELECT a2.Artist, a2.plays FROM \\\n",
    "          (SELECT max(plays) AS max_plays FROM artist_counts) AS a1 \\\n",
    "          JOIN artist_counts AS a2 \\\n",
    "          ON a1.max_plays = a2.plays \\\n",
    "          \").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e4959b",
   "metadata": {},
   "source": [
    "# Question 5 (challenge)\n",
    "\n",
    "Quantas músicas os usuários ouvem em média entre as visitas à nossa página inicial? Arredonde sua resposta para o número inteiro mais próximo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3672b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELECT CASE WHEN 1 > 0 THEN 1 WHEN 2 > 0 THEN 2.0 ELSE 1.2 END;\n",
    "\n",
    "is_home = spark.sql(\"SELECT userId, page, ts, CASE WHEN page = 'Home' \\\n",
    "                THEN 1 ELSE 0 END AS is_home FROM TABLE \\\n",
    "                where (page = 'NextSong') or (page = 'Home') \\\n",
    "                \")\n",
    "\n",
    "# Keep the results in a new view\n",
    "is_home.createOrReplaceTempView('is_home_table')\n",
    "\n",
    "# find the cumulative sum over the is_home column\n",
    "cumulative_sum = spark.sql(\"SELECT *, SUM(is_home) OVER \\\n",
    "            (PARTITION BY userId ORDER BY ts DESC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS period \\\n",
    "            FROM is_home_table\")\n",
    "\n",
    "# Keep the result in a View\n",
    "cumulative_sum.createOrReplaceTempView(\"period_table\")\n",
    "\n",
    "# find the averange count for NextSong\n",
    "spark.sql(\"SELECT AVG(count_results) FROM \\\n",
    "        (SELECT COUNT(*) AS count_results FROM period_table \\\n",
    "GROUP BY userId, period, page HAVING page = 'NestSong') AS counts\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd0b599",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f141bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4f1259",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4a0c90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3395a78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b660929",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
