{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af8eb014",
   "metadata": {},
   "source": [
    "# Consultancy: Semantix\n",
    "\n",
    "## Customer: Santander\n",
    "\n",
    "#### Data Enginner: Rodolfo Terra\n",
    "\n",
    "#### Date: 2021 - 12 - 02\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42c4984",
   "metadata": {},
   "source": [
    "# TESTE DE CONHECIMENTO APLICAVEL\n",
    "\n",
    "iga os passos de pré-requisitos e faça upload do arquivo cadastro.csv e ranking.csv no espaço informado, o arquivo será carregado para dentro do ambiente dbfs do databricks\n",
    "\n",
    "### Listando diretorios\n",
    "display(dbutils.fs.ls(\"dbfs:/FileStore/tables\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf29cf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages -------------------------------\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.functions import desc\n",
    "from pyspark.sql.functions import asc\n",
    "from pyspark.sql.functions import sum as Fsum\n",
    "\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69df0e4",
   "metadata": {},
   "source": [
    "## Questões\n",
    "\n",
    "Utilizando o DataFrame df responda as questões abaixo:\n",
    "\n",
    "### 1.    Adicionar 1 coluna com um contador sequencial por Município e ordenar por Estado; Nomear \"agrupador\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b15fc7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"wranglig_data_santander\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcfb1933",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data_santander/cadastro.csv\"\n",
    "df = spark.read.csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95c5b3c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-----------+-----------------+----------+\n",
      "|_c0|     _c1|        _c2|              _c3|       _c4|\n",
      "+---+--------+-----------+-----------------+----------+\n",
      "|  1|    Jose|   Anapolis|        Sao Paulo|01/09/1900|\n",
      "|  3|Leonardo|   Anapolis|        Sao Paulo|21/12/2000|\n",
      "|  2|    Igor|   Anapolis|        Sao Paulo|11/09/1977|\n",
      "|  5|Humberto|Pato Branco|Rio Grande do Sul|13/11/1964|\n",
      "|  4|   Pedro|  Sao Paulo|        Sao Paulo|18/01/2000|\n",
      "|  6|  Isaias|Pato Branco|Rio Grande do Sul|07/07/2002|\n",
      "|  7|   Lucas|       Taua|            Ceara|05/09/1984|\n",
      "|  8| Marcelo|     Osasco|        Sao Paulo|07/01/1992|\n",
      "+---+--------+-----------+-----------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54de2677",
   "metadata": {},
   "source": [
    "### 2.    Adicionar 1 coluna com a Idade em anos; Nomear \"idade\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2bf7fd37",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "col should be Column",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-166afddf74bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"idade\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mwithColumn\u001b[0;34m(self, colName, col)\u001b[0m\n\u001b[1;32m   2475\u001b[0m         \"\"\"\n\u001b[1;32m   2476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2477\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"col should be Column\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2478\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: col should be Column"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"idade\",10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643f54cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6781f7a2",
   "metadata": {},
   "source": [
    "### 3.    Adicionar 1 coluna com a data de atualização, preenchendo com a data do dia da execução, formatar como dia-mes-ano(dd/MM/yyyy); Nomear \"dt_atualizacao\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e41e14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e640f36e",
   "metadata": {},
   "source": [
    "### 4.    Atualizar coluna cod_usuario, formatar o campo com 3 posições a esquerda completando com “0”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952e56f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7ba8a38",
   "metadata": {},
   "source": [
    "### 5.    Transfira as modificações para um novo DataFrame nomeado dfCadastro e exiba o resultado das modificações acima ordenando pelo campo cod_usuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45e82af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "14a7e7e8",
   "metadata": {},
   "source": [
    "## Enriquecendo nossa base\n",
    "Faça upload do arquivo ranking.csv e carregue em um dataframe com o nome dfRanking\n",
    "\n",
    "/FileStore/tables/ranking.csv\n",
    "\n",
    "1.    Schema do arquivo ranking.csv:\n",
    "\n",
    "    *    cod_ranking\n",
    "\n",
    "    *    cod_usuario\n",
    "\n",
    "    *    ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6d07ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe412e8a",
   "metadata": {},
   "source": [
    "## Questões\n",
    "Crie um novo dataframe dentro das condições abaixo:\n",
    "\n",
    "### 1.    Relacione os dois DataFrames, cadastro e ranking, para avaliarmos a classificação de nossos usuarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae618c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5281b39c",
   "metadata": {},
   "source": [
    "### 2.    filtre apenas os usuarios que possuem algum ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce5e4da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84aa3261",
   "metadata": {},
   "source": [
    "### 3.    Selecione apenas as colunas cod_usuario, nome, ranking, idade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6944bf34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3d00b2d2",
   "metadata": {},
   "source": [
    "### 4.    Exiba quantos usuarios possuem valor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715aa9a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "16d1b28a",
   "metadata": {},
   "source": [
    "# Teste Conceitual\n",
    "Defina a diferença de transformação e ação dentro do conceito \"lazy evaluation\" do spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a58d0e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa205f6b",
   "metadata": {},
   "source": [
    "### Defina o que é ação e transformação para os itens abaixo:\n",
    "\n",
    "·         show\n",
    "\n",
    "·         join\n",
    "\n",
    "·         groupBy\n",
    "\n",
    "·         count\n",
    "\n",
    "·         sum\n",
    "\n",
    "·         withColumn\n",
    "\n",
    "·         write\n",
    "\n",
    "·         select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00337b26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83c08777",
   "metadata": {},
   "source": [
    "### Qual das maneiras abaixo é possível ordenar os feature \"requests\" decrescente,\n",
    "\n",
    "·         df.orderBy(\"requests desc\")\n",
    "\n",
    "·         df.orderBy(\"requests\").desc()\n",
    "\n",
    "·         df.orderBy(col(\"requests\").desc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12c21fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "600fc36b",
   "metadata": {},
   "source": [
    "### Muitos arquivos pequenos geram conflito na continuidade da leitura e transformação do dado.\n",
    "\n",
    "Qual comando podemos utilizar ou de qual maneira podemos fazer para minimizar o problema de \"small files\" gerado na gravação do parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426aaaa3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5ab3a6c8",
   "metadata": {},
   "source": [
    "# Teste final\n",
    "Descrição da Tarefa:\n",
    "·         Dado um dataframe com duas colunas [id_cliente, categorias].\n",
    "\n",
    "·         Fazer um dataframe resultado, com uma coluna pra cada tipo de categoria, com valor 1 caso aquela categoria exista e 0 caso não exista, isso para cada cliente (one-hot-encoded).\n",
    "\n",
    "·         Regras:\n",
    "\n",
    "o    Pode usar qualquer biblioteca auxiliar.\n",
    "\n",
    "o    O número de categorias é dinamico e não conhecido de antemão.\n",
    "\n",
    "o    O script tem que funcionar para os dois dataframes exemplos.\n",
    "\n",
    "o    Os seus dataframes resposta têm que ser exatamente iguais aos apresentados no documento.\n",
    "\n",
    "o    O script deve executar com o menor tempo possível.\n",
    "\n",
    "Obs: resultado esperado encontra-se no documento entregue para o teste\n",
    "\n",
    "Elaboração do teste realizado por Samuel Otero Schmidt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d168bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebb3605",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f000267e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf3be4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed3de56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa88b2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a285a37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2b4a37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5374b2fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff2c467",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242e6ad4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3465ff62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ae8857",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
